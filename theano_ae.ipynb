{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import theano.tensor as T \n",
    "import theano\n",
    "import sys\n",
    "sys.path.insert(0,\"eigengenes\")\n",
    "import load_data\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# uncomment if running in ipython notebook\n",
    "#sys.argv = ['test.py', 'bthet', '2']\n",
    "\n",
    "#ecoli\n",
    "#bthet\n",
    "species = sys.argv[1]\n",
    "numhidden = int(sys.argv[2])\n",
    "data =  load_data.load(species, False)[0]\n",
    "datashape =  data.shape\n",
    "data = np.array(data,dtype=theano.config.floatX)\n",
    "data = theano.shared(data,name = 'data', borrow = True)\n",
    "#data = np.array(data,dtype=theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=numhidden)\n",
    "pca_embedding = pca.fit_transform(data.eval())\n",
    "pca_reconstruction = pca.inverse_transform(pca_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr = T.dscalar()\n",
    "if False:\n",
    "    #######################################################\n",
    "    ### Here is a standard linear tied weight autoencoder\n",
    "    ### This should match PCA reconstruction error\n",
    "    ### Gradient clipping is used for training\n",
    "    model_desc = str(datashape[1]) + \"x\" + str(numhidden) + \"x\" + str(datashape[1]);\n",
    "\n",
    "    #define the weights of the model \n",
    "    w1 = theano.shared (value = np.random.uniform(low=-1.0, high=1.0 , size=(datashape[1],numhidden)))\n",
    "\n",
    "    if (False):\n",
    "        allparams = pickle.load( open( model_desc + \"_params.p\", \"rb\" ))\n",
    "    else:\n",
    "        allparams = [w1]\n",
    "\n",
    "    w1 = allparams[0]\n",
    "\n",
    "    #define the core of the model\n",
    "    inputx = T.matrix ()\n",
    "    hidden = T.dot(inputx, theano.gradient.grad_clip(w1,-1,1))\n",
    "    output = T.dot(hidden, theano.gradient.grad_clip(w1.T,-1,1))\n",
    "    \n",
    "    #define loss function\n",
    "    L = T.mean(T.sum((inputx-output)**2, axis=1))\n",
    "    \n",
    "    updates = [(w1, w1 - lr * T.grad(cost = L, wrt = w1))]\n",
    "\n",
    "elif False:\n",
    "    #######################################################\n",
    "    ### Here is a linear autoencoder (without bias though)\n",
    "    ### Gradient clipping is used for training\n",
    "    ### The loss function is combined with pca reconstruction in hidden layer\n",
    "    model_desc = str(datashape[1]) + \"x\" + str(numhidden) + \"x\" + str(datashape[1]);\n",
    "\n",
    "    #define the weights of the model \n",
    "    w1 = theano.shared (value = np.random.uniform(low=-1.0, high=1.0 , size=(datashape[1],numhidden)))\n",
    "    w2 = theano.shared (value = np.random.uniform(low=-1.0, high=1.0 , size=(numhidden, datashape[1])))\n",
    "\n",
    "    if (False):\n",
    "        allparams = pickle.load( open( model_desc + \"_params.p\", \"rb\" ))\n",
    "    else:\n",
    "        allparams = [w1, w2]\n",
    "\n",
    "    w1, w2 = allparams\n",
    "\n",
    "    #define the core of the model\n",
    "    inputx = T.matrix ()\n",
    "    hidden = T.dot(inputx, theano.gradient.grad_clip(w1,-1,1))\n",
    "    output = T.dot(hidden, theano.gradient.grad_clip(w2,-1,1))\n",
    "    \n",
    "    #define loss function\n",
    "    L = 0.8*T.mean(T.sum((inputx-output)**2, axis=1)) + 0.2*T.mean(T.sum((pca_embedding-hidden)**2, axis=1))\n",
    "    \n",
    "    updates = [(x, x - lr * T.grad(cost = L, wrt = x)) for x in allparams]\n",
    "    \n",
    "elif True:\n",
    "    #######################################################\n",
    "    ### Here is a deep non-linear autoencoder\n",
    "    ### The loss function is combined with pca reconstruction in hidden layer\n",
    "    \n",
    "    numhidden0 = 4\n",
    "    numhidden1 = 4\n",
    "    model_desc = str(datashape[1]) + \"x\" + str(numhidden0) + \"x\" + str(numhidden)+ \"x\" + str(numhidden1) + \"x\" + str(datashape[1]);\n",
    "\n",
    "    #define the weights of the model \n",
    "    w1 = theano.shared (value = np.random.uniform(low=-1.0, high=1.0 , size=(datashape[1],numhidden0)))\n",
    "    w2 = theano.shared (value = np.random.uniform(low=-1.0, high=1.0 , size=(numhidden0,numhidden)))\n",
    "    w3 = theano.shared (value = np.random.uniform(low=-1.0, high=1.0 , size=(numhidden,numhidden1)))\n",
    "    w4 = theano.shared (value = np.random.uniform(low=-1.0, high=1.0 , size=(numhidden1,datashape[1])))\n",
    "    \n",
    "    b1 = theano.shared (value = np.zeros(numhidden0))\n",
    "    b2 = theano.shared (value = np.zeros(numhidden))\n",
    "    b3 = theano.shared (value = np.zeros(numhidden1))\n",
    "    b4 = theano.shared (value = np.zeros(datashape[1]))\n",
    "\n",
    "    if (False):\n",
    "        allparams = pickle.load( open( model_desc + \"_params.p\", \"rb\" ))\n",
    "    else:\n",
    "        allparams = [w1, w2, w3, w4, b1, b2, b3, b4]\n",
    "\n",
    "    w1, w2, w3, w4, b1, b2, b3, b4 = allparams\n",
    "    \n",
    "    inputx = T.matrix ()\n",
    "\n",
    "    hidden0 = theano.tensor.tanh(T.dot(inputx, theano.gradient.grad_clip(w1,-1,1)) + theano.gradient.grad_clip(b1,-1,1))\n",
    "    hidden = theano.tensor.tanh(T.dot(hidden0, theano.gradient.grad_clip(w2,-1,1)) + theano.gradient.grad_clip(b2,-1,1))\n",
    "    hidden1 = theano.tensor.tanh(T.dot(hidden, theano.gradient.grad_clip(w3,-1,1)) + theano.gradient.grad_clip(b3,-1,1))\n",
    "    output = theano.tensor.tanh(T.dot(hidden1, theano.gradient.grad_clip(w4,-1,1)) + theano.gradient.grad_clip(b4,-1,1))\n",
    "    \n",
    "    #define loss function\n",
    "    L = T.mean(T.sum((inputx-output)**2, axis=1)) + T.mean(T.sum((pca_embedding-hidden)**2, axis=1))\n",
    "\n",
    "    updates = [(x, x - lr * T.grad(cost = L, wrt = x)) for x in allparams]\n",
    "        \n",
    "print(\"Model shape \" + model_desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define method to train each epoch\n",
    "train_model = theano.function(\n",
    "    inputs=[lr],\n",
    "    outputs=L,\n",
    "    updates=updates,\n",
    "    givens = {\n",
    "        inputx: data\n",
    "    }\n",
    ")\n",
    "\n",
    "#define how to make prediction\n",
    "ae_reconstruct = theano.function(\n",
    "    inputs=[inputx],\n",
    "    outputs=output,\n",
    ")\n",
    "\n",
    "#define how to output embedding\n",
    "ae_embed = theano.function(\n",
    "    inputs=[inputx],\n",
    "    outputs=hidden,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    lr = 0.01\n",
    "    for i in range(2):\n",
    "        print \"Learning rate: {}\".format(lr)\n",
    "        olderror = float(\"inf\")\n",
    "        for i in range(1000):\n",
    "            error = train_model(lr)\n",
    "            if i%50 == 0: \n",
    "                print \"Epoch: {:>04}, Mean Squared Error: {}\".format(i,error)\n",
    "                if  (error + 0.01) > olderror:\n",
    "                    print \"Inner Loop End\"\n",
    "                    break\n",
    "                olderror = error\n",
    "                sys.stdout.flush()\n",
    "                pickle.dump(allparams, open( model_desc + \"_params.p\", \"wb\" ) )\n",
    "        lr = lr * 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ae_embedding = ae_embed(data.eval())\n",
    "#ae_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if show:\n",
    "    %matplotlib inline\n",
    "    plt.plot(ae_embedding[:,0], ae_embedding[:,1], 'ro')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#results = PCA(data)\n",
    "pca = PCA(n_components=numhidden)\n",
    "pca_embedding = pca.fit_transform(data.eval())\n",
    "pca_reconstruction = pca.inverse_transform(pca_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if show:\n",
    "    %matplotlib inline\n",
    "    plt.plot(pca_embedding[:,0], pca_embedding[:,1], 'ro')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## PCA reconstruction error\n",
    "print \"pca_reconstruction, species, {}, numhidden, {}, error, {}\".format(species, numhidden,(np.sum((pca_reconstruction - data.eval())**2, axis=1)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## AE reconstruction error\n",
    "ae_reconstruction = ae_reconstruct(data.eval())\n",
    "print \"ae_reconstruction, species, {}, numhidden, {}, error, {}\".format(species, numhidden,(np.sum((ae_reconstruction - data.eval())**2, axis=1)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
